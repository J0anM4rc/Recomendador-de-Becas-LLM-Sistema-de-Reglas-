# Chatbot de BÃºsqueda de Becas

Un asistente conversacional en lenguaje natural para guiar a estudiantes en la bÃºsqueda de becas, apoyado por un modelo LLM local (LLAMAÂ 3.2) y un motor lÃ³gico Prolog.

---

## ğŸ† CaracterÃ­sticas

- BÃºsqueda por **cÃ³digo de beca** o por **criterios** (Ã¡rea, financiaciÃ³n, lugarâ€¦).  
- Explicaciones de criterios bajo demanda.  
- EdiciÃ³n de filtros en cualquier momento.  
- Flujo guiado 100â€¯% en lenguaje natural (sin botones).  
- Arquitectura modular con **Clean Architecture** y **Chain of Responsibility**.

---

## ğŸ“ Arquitectura general

1. **Domain**: entidades (`Scholarship`, `FilterCriteria`) y **interfaces** (`ScholarshipRepository`, `IntentClassifierService`).  
2. **Application**: casos de uso (`SearchByCode`, `FilterScholarship`, `ExplainCriterion`, etc.) y pipeline de handlers (`PreprocessHandler`, `IntentHandler`, `FlowHandler`, `GenerationHandler`).  
3. **Infrastructure**: adaptadores concretos para Prolog (`PrologScholarshipRepository`) y LLM (`LLAMAInterface` o stub).  
4. **Presentation**: API REST/WebSocket con FastAPI.

---

## ğŸš€ Primeros pasos

### Requisitos previos

- PythonÂ 3.10+  
- Git  
- (Opcional) Docker  

### InstalaciÃ³n local

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/chatbot-becas.git
cd chatbot-becas

# Crear y activar entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```  

### Variables de entorno

Crea un archivo `.env` con las rutas a tu modelo y KB de Prolog:

```env
LLAMA_PATH=./models/llama-3.2
PROLOG_KB=./becas.pl
```  

### Ejecutar el servidor

```bash
uvicorn src.presentation.api:app --reload
```  
API disponible en `http://127.0.0.1:8000`.

---

## ğŸ—‚ï¸ Estructura del proyecto

```text
project-root/
â”œâ”€â”€ config/                # flujos, mapeos y glosario en JSON
â”‚   â”œâ”€â”€ flow_config.json
â”‚   â”œâ”€â”€ mappings.json
â”‚   â””â”€â”€ glossary.json
â”œâ”€â”€ docs/                  # documentaciÃ³n viva: visiÃ³n, flujos, personas
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/            # entidades e interfaces puras
â”‚   â”œâ”€â”€ application/       # casos de uso y pipeline de handlers
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ pipeline/
â”‚   â”œâ”€â”€ infrastructure/    # adaptadores (Prolog, LLM, repositorios JSON)
â”‚   â””â”€â”€ presentation/      # FastAPI (endpoints REST/WebSocket)
â”œâ”€â”€ tests/                 # tests unitarios e integraciÃ³n
â”œâ”€â”€ main.py                # punto de entrada opcional
â”œâ”€â”€ README.md
â””â”€â”€ Dockerfile
```  

---

## âœ… Testing

```bash
# Ejecutar tests unitarios e integraciÃ³n
pytest --maxfail=1 --disable-warnings -q
```  

---

## ğŸ›£ï¸ Roadmap

1. **SprintÂ 1**: stubs e infraestructura mÃ­nima + pipeline de juguete + endpoint `/chat`.  
2. **SprintÂ 2**: implementar PrologConnector y SearchByCode completos.  
3. **SprintÂ 3**: extracciÃ³n de criterios y FilterScholarship.  
4. **SprintÂ 4**: explicaciones de criterios y editar filtros.  
5. **SprintÂ 5**: pruebas de usuario y optimizaciÃ³n de prompts de LLAMA.

---

## ğŸ¤ Contribuir

1. Haz un _fork_  
2. Crea una _branch_ feature: `git checkout -b feature/tu-idea`  
3. Realiza tus cambios y _commitea_  
4. Abre un _pull request_  

---

## ğŸ“„ Licencia

[MIT](LICENSE)
